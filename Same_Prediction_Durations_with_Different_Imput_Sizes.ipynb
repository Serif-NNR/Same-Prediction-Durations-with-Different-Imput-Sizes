{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Şerif İnanır, 08.02.2023, \n",
        "Written for this topic: https://discuss.pytorch.org/t/how-to-control-tensor-size-inside-of-functional-files-in-c/172027"
      ],
      "metadata": {
        "id": "pt9DscRa07hZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pk-JtqJT00wf"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels))\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels//2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "        \n",
        "        x1 = F.pad(x1, [diffX//2, diffX-diffX//2,\n",
        "                        diffY//2, diffY-diffY//2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "LRvnRcGb117a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "        factor = 2 if bilinear else 1\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 8)\n",
        "        self.down1 = Down(8, 16)\n",
        "        self.down2 = Down(16, 32)\n",
        "        self.down3 = Down(32, 64//factor)\n",
        "        self.up2 = Up(64, 32//factor, bilinear)        \n",
        "        self.up3 = Up(32, 16//factor, bilinear)        \n",
        "        self.up4 = Up(16, 8, bilinear)        \n",
        "        self.outc = OutConv(8, n_classes)\n",
        "  \n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x = self.up2(x4, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "AR-7I8171hTi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_prediction_durations(first_tensor, second_tensor, loop_count=100, experiment_count=5):\n",
        "  devs = [\"cuda:0\", \"cpu\"]\n",
        "  tensors = [first_tensor, second_tensor]\n",
        "  def calculate(model, tensor, device, loop_count):\n",
        "    durations = []\n",
        "    outset = None\n",
        "    for i in range(loop_count):\n",
        "      outset = time.time()\n",
        "      model(tensor.to(device))\n",
        "      durations.append(time.time()-outset)\n",
        "    return np.mean(durations)\n",
        "  for  exp in range(1, experiment_count+1):\n",
        "    for dev in devs:\n",
        "      #model = UNet(1, 1).to(dev)\n",
        "      for tensor in tensors:\n",
        "        model = UNet(1, 1).to(dev)\n",
        "        print(\"[EXP {0:4d}]\\tDevice: {1:10s}\\tInput Size: {2:20s}\\tMean Prediction Duration: {3:10f}\".format(exp, dev, str(tensor.shape), calculate(model, tensor, dev, loop_count)))\n",
        "    print(\"\\n\")\n",
        "\n",
        "calculate_prediction_durations(first_tensor=torch.randn(1, 1, 256, 256), second_tensor=torch.randn(1, 1, 128, 128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO5mELjo2Kzk",
        "outputId": "fb91891f-3b25-4d38-81dc-ed5b192e1d15"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EXP    1]\tDevice: cuda:0    \tInput Size: torch.Size([1, 1, 256, 256])\tMean Prediction Duration:   0.003935\n",
            "[EXP    1]\tDevice: cuda:0    \tInput Size: torch.Size([1, 1, 128, 128])\tMean Prediction Duration:   0.003833\n",
            "[EXP    1]\tDevice: cpu       \tInput Size: torch.Size([1, 1, 256, 256])\tMean Prediction Duration:   0.063018\n",
            "[EXP    1]\tDevice: cpu       \tInput Size: torch.Size([1, 1, 128, 128])\tMean Prediction Duration:   0.020142\n",
            "\n",
            "\n",
            "[EXP    2]\tDevice: cuda:0    \tInput Size: torch.Size([1, 1, 256, 256])\tMean Prediction Duration:   0.004703\n",
            "[EXP    2]\tDevice: cuda:0    \tInput Size: torch.Size([1, 1, 128, 128])\tMean Prediction Duration:   0.003693\n",
            "[EXP    2]\tDevice: cpu       \tInput Size: torch.Size([1, 1, 256, 256])\tMean Prediction Duration:   0.060208\n",
            "[EXP    2]\tDevice: cpu       \tInput Size: torch.Size([1, 1, 128, 128])\tMean Prediction Duration:   0.014611\n",
            "\n",
            "\n",
            "[EXP    3]\tDevice: cuda:0    \tInput Size: torch.Size([1, 1, 256, 256])\tMean Prediction Duration:   0.004006\n",
            "[EXP    3]\tDevice: cuda:0    \tInput Size: torch.Size([1, 1, 128, 128])\tMean Prediction Duration:   0.003821\n",
            "[EXP    3]\tDevice: cpu       \tInput Size: torch.Size([1, 1, 256, 256])\tMean Prediction Duration:   0.064664\n",
            "[EXP    3]\tDevice: cpu       \tInput Size: torch.Size([1, 1, 128, 128])\tMean Prediction Duration:   0.015054\n",
            "\n",
            "\n",
            "[EXP    4]\tDevice: cuda:0    \tInput Size: torch.Size([1, 1, 256, 256])\tMean Prediction Duration:   0.004037\n",
            "[EXP    4]\tDevice: cuda:0    \tInput Size: torch.Size([1, 1, 128, 128])\tMean Prediction Duration:   0.003747\n",
            "[EXP    4]\tDevice: cpu       \tInput Size: torch.Size([1, 1, 256, 256])\tMean Prediction Duration:   0.062987\n",
            "[EXP    4]\tDevice: cpu       \tInput Size: torch.Size([1, 1, 128, 128])\tMean Prediction Duration:   0.016053\n",
            "\n",
            "\n",
            "[EXP    5]\tDevice: cuda:0    \tInput Size: torch.Size([1, 1, 256, 256])\tMean Prediction Duration:   0.004154\n",
            "[EXP    5]\tDevice: cuda:0    \tInput Size: torch.Size([1, 1, 128, 128])\tMean Prediction Duration:   0.004020\n",
            "[EXP    5]\tDevice: cpu       \tInput Size: torch.Size([1, 1, 256, 256])\tMean Prediction Duration:   0.056365\n",
            "[EXP    5]\tDevice: cpu       \tInput Size: torch.Size([1, 1, 128, 128])\tMean Prediction Duration:   0.015063\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}